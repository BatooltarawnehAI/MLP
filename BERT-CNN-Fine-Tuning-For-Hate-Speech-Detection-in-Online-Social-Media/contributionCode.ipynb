{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMPFOYXGOiUOGwbSNtWue1R"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LF7dvdwQaWE9","executionInfo":{"status":"ok","timestamp":1733072099392,"user_tz":300,"elapsed":1069,"user":{"displayName":"Batool Altarawneh","userId":"05940811569473459277"}},"outputId":"9d8666c9-0997-4660-b3f0-701e1f154429"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import zipfile\n","import os\n","\n","project_path=\"/content/drive/MyDrive/Project/BERT-CNN-Fine-Tuning-For-Hate-Speech-Detection-in-Online-Social-Media\"\n","# Replace 'your_file.zip' with the actual name of your uploaded zip file\n","os.chdir(project_path)\n","print(\"current dir\",os.getcwd())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vicZyWKealbQ","executionInfo":{"status":"ok","timestamp":1733072099392,"user_tz":300,"elapsed":4,"user":{"displayName":"Batool Altarawneh","userId":"05940811569473459277"}},"outputId":"d99caf8d-9d76-4940-f5b7-fb4cdaea113a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["current dir /content/drive/MyDrive/Project/BERT-CNN-Fine-Tuning-For-Hate-Speech-Detection-in-Online-Social-Media\n"]}]},{"cell_type":"code","source":["\n","files = os.listdir()\n","print(\"Files in directory:\", files)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"56Slud1xaoQo","executionInfo":{"status":"ok","timestamp":1733072099392,"user_tz":300,"elapsed":3,"user":{"displayName":"Batool Altarawneh","userId":"05940811569473459277"}},"outputId":"f639943c-59df-44f3-b4d0-b1a1b2d1a114"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Files in directory: ['LICENSE', 'BertCnnFinal.ipynb', 'README.md', 'BERT-CNN-Demo.mp4', 'labeled_data.csv', 'Images', '.ipynb_checkpoints', '.git', '__pycache__', 'Pre_Process.py', 'Model.py', 'BertCNN.py', 'Untitled3.ipynb']\n"]}]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/drive/MyDrive/Project/BERT-CNN-Fine-Tuning-For-Hate-Speech-Detection-in-Online-Social-Media')\n"],"metadata":{"id":"eCRFOFMvrBuV","executionInfo":{"status":"ok","timestamp":1733072100420,"user_tz":300,"elapsed":2,"user":{"displayName":"Batool Altarawneh","userId":"05940811569473459277"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import importlib.util\n","\n","# Define the full path to Model.py\n","model_path = \"/content/drive/MyDrive/Project/BERT-CNN-Fine-Tuning-For-Hate-Speech-Detection-in-Online-Social-Media/Model.py\"\n","\n","# Load Model.py dynamically\n","spec = importlib.util.spec_from_file_location(\"Model\", model_path)\n","Model = importlib.util.module_from_spec(spec)\n","spec.loader.exec_module(Model)\n","\n","# Use the imported class or function\n","BERT_CNN = Model.BERT_CNN\n"],"metadata":{"id":"-eC9diS1rGyL","executionInfo":{"status":"ok","timestamp":1733072103652,"user_tz":300,"elapsed":168,"user":{"displayName":"Batool Altarawneh","userId":"05940811569473459277"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["model_path = \"/content/drive/MyDrive/Project/BERT-CNN-Fine-Tuning-For-Hate-Speech-Detection-in-Online-Social-Media/Pre_Process.py\"\n","spec1 = importlib.util.spec_from_file_location(\"Model\", model_path)\n","Pre_Process = importlib.util.module_from_spec(spec1)\n","spec1.loader.exec_module(Pre_Process)\n","\n","# Use the imported class or function\n","load_and_process = Pre_Process.load_and_process\n"],"metadata":{"id":"LuCIH6_rwuNd","executionInfo":{"status":"ok","timestamp":1733072106464,"user_tz":300,"elapsed":180,"user":{"displayName":"Batool Altarawneh","userId":"05940811569473459277"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# pip install emoji"],"metadata":{"id":"Z-Br6Eidj2MK","executionInfo":{"status":"ok","timestamp":1733072109959,"user_tz":300,"elapsed":202,"user":{"displayName":"Batool Altarawneh","userId":"05940811569473459277"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["import gc\n","import re\n","import string\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, accuracy_score\n","from transformers import BertModel, BertTokenizer\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","# Device setup\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\")\n","\n","# Define the BERT-large model architecture\n","class BERT_Arch(nn.Module):\n","    def __init__(self, bert):\n","        super(BERT_Arch, self).__init__()\n","        self.bert = bert\n","\n","        # CNN layers\n","        self.conv = nn.Conv2d(in_channels=25, out_channels=25, kernel_size=(3, 1024), padding=(1, 0))\n","        self.relu = nn.ReLU()\n","        self.pool = nn.MaxPool2d(kernel_size=(3, 1), stride=(1, 1))\n","        self.dropout = nn.Dropout(0.1)\n","\n","        # Dynamically calculate the flattened size for the fc layer\n","        self._initialize_fc_layer()\n","\n","    def _initialize_fc_layer(self):\n","        # Dummy input to calculate the flattened size dynamically\n","        dummy_input = torch.zeros(1, 25, 36, 1024)  # (batch_size, in_channels, seq_length, hidden_size)\n","        dummy_output = self.pool(self.dropout(self.relu(self.conv(self.dropout(dummy_input)))))\n","        flattened_size = dummy_output.numel()  # Total number of elements\n","        self.flat = nn.Flatten()\n","        self.fc = nn.Linear(flattened_size, 3)  # Update the size dynamically\n","        self.softmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, sent_id, mask):\n","        # Get all hidden states (25 layers for bert-large-uncased)\n","        outputs = self.bert(sent_id, attention_mask=mask, output_hidden_states=True)\n","        all_layers = torch.stack(outputs.hidden_states, dim=0)  # Shape: (25, batch_size, seq_length, hidden_size)\n","\n","        # Permute to shape (batch_size, 25, seq_length, hidden_size)\n","        x = all_layers.permute(1, 0, 2, 3)\n","\n","        # Apply CNN and fully connected layers\n","        x = self.pool(self.dropout(self.relu(self.conv(self.dropout(x)))))\n","        x = self.flat(x)\n","        x = self.fc(self.dropout(x))\n","        return self.softmax(x)\n","\n","# Preprocessing functions\n","def read_dataset():\n","    data = pd.read_csv(\"labeled_data.csv\")\n","    data = data.drop(['count', 'hate_speech', 'offensive_language', 'neither'], axis=1)\n","    print(f\"Dataset size: {len(data)}\")\n","    return data['tweet'].tolist(), data['class']\n","\n","def pre_process_dataset(values):\n","    processed_values = []\n","    for value in values:\n","        text = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", value.lower())\n","        text = re.sub(r\"([?.!,¿])\", r\" \", text)\n","        text = \"\".join(l for l in text if l not in string.punctuation)\n","        text = re.sub(r'[\" \"]+', \" \", text)\n","        processed_values.append(text.strip())\n","    return processed_values\n","\n","def data_process(data, labels):\n","    input_ids = []\n","    attention_masks = []\n","    tokenizer = BertTokenizer.from_pretrained(\"bert-large-uncased\")\n","\n","    for sentence in data:\n","        bert_input = tokenizer(sentence, max_length=36, padding='max_length', truncation=True, return_tensors=\"pt\")\n","        input_ids.append(bert_input['input_ids'].squeeze(0))\n","        attention_masks.append(bert_input['attention_mask'].squeeze(0))\n","\n","    input_ids = torch.stack(input_ids)\n","    attention_masks = torch.stack(attention_masks)\n","    labels = torch.tensor(labels.values if isinstance(labels, pd.Series) else labels)\n","\n","    return input_ids, attention_masks, labels\n","\n","def load_and_process():\n","    data, labels = read_dataset()\n","    data = pre_process_dataset(data)\n","    return data_process(data, labels)\n","\n","# Training and evaluation functions\n","def train():\n","    model.train()\n","    total_loss, total_preds = 0, []\n","\n","    for step, batch in enumerate(train_dataloader):\n","        sent_id, mask, labels = [item.to(device) for item in batch]\n","        model.zero_grad()\n","\n","        preds = model(sent_id, mask)\n","        loss = cross_entropy(preds, labels)\n","        total_loss += loss.item()\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","\n","        total_preds.append(preds.detach().cpu())\n","\n","    return total_loss / len(train_dataloader), torch.cat(total_preds)\n","\n","def evaluate():\n","    model.eval()\n","    total_loss, total_preds = 0, []\n","\n","    with torch.no_grad():\n","        for step, batch in enumerate(val_dataloader):\n","            sent_id, mask, labels = [item.to(device) for item in batch]\n","\n","            preds = model(sent_id, mask)\n","            loss = cross_entropy(preds, labels)\n","            total_loss += loss.item()\n","            total_preds.append(preds.detach().cpu())\n","\n","    return total_loss / len(val_dataloader), torch.cat(total_preds)\n","\n","# Main script\n","input_ids, attention_masks, labels = load_and_process()\n","\n","# Split the dataset\n","train_inputs, val_inputs, train_labels, val_labels = train_test_split(input_ids, labels, test_size=0.1, random_state=42)\n","train_masks, val_masks = train_test_split(attention_masks, test_size=0.1, random_state=42)\n","\n","# Create DataLoaders\n","train_dataset = TensorDataset(train_inputs, train_masks, train_labels)\n","val_dataset = TensorDataset(val_inputs, val_masks, val_labels)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_dataloader = DataLoader(val_dataset, batch_size=32)\n","\n","# Initialize the model\n","bert = BertModel.from_pretrained('bert-large-uncased', output_hidden_states=True)\n","model = BERT_Arch(bert).to(device)\n","\n","# Optimizer and loss function\n","optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n","cross_entropy = nn.CrossEntropyLoss()\n","\n","# Training loop\n","epochs = 3\n","for epoch in range(epochs):\n","    print(f\"Epoch {epoch + 1} of {epochs}\")\n","    train_loss, _ = train()\n","    val_loss, _ = evaluate()\n","    print(f\"Train Loss: {train_loss}, Validation Loss: {val_loss}\")\n","\n","# Evaluation on validation data\n","val_loss, val_preds = evaluate()\n","val_preds = torch.argmax(val_preds, axis=1)\n","\n","print(\"\\nValidation Performance:\")\n","print(classification_report(val_labels, val_preds))\n","print(f\"Accuracy: {accuracy_score(val_labels, val_preds):.4f}\")\n","torch.cuda.empty_cache()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1zJvpUicatHQ","executionInfo":{"status":"ok","timestamp":1733074829512,"user_tz":300,"elapsed":1720136,"user":{"displayName":"Batool Altarawneh","userId":"05940811569473459277"}},"outputId":"009b958d-c9cb-48fd-bac5-cd15f9b1002b"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","Dataset size: 24783\n","Epoch 1 of 3\n","Train Loss: 0.30312098621242445, Validation Loss: 0.2718863500138888\n","Epoch 2 of 3\n","Train Loss: 0.21480255684089797, Validation Loss: 0.2624606180171936\n","Epoch 3 of 3\n","Train Loss: 0.15158758307787104, Validation Loss: 0.29335811753303576\n","\n","Validation Performance:\n","              precision    recall  f1-score   support\n","\n","           0       0.52      0.35      0.42       164\n","           1       0.92      0.96      0.94      1905\n","           2       0.91      0.84      0.88       410\n","\n","    accuracy                           0.90      2479\n","   macro avg       0.78      0.72      0.75      2479\n","weighted avg       0.89      0.90      0.90      2479\n","\n","Accuracy: 0.9028\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"uBllQaL1cO6p"},"execution_count":null,"outputs":[]}]}